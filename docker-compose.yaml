services:
  ollama:
    image: ollama/ollama:latest
    pull_policy: always
    entrypoint: /bin/sh -c
    command: |
      "ollama pull llama3:8b && 
      ollama serve"
    container_name: ollama
    tty: true
    ports:
      - 11434:11434
    volumes:
      - ollama:/root/.ollama
    networks:
      - ollama
  
  web:
    build:
      context: ./web
      dockerfile: Dockerfile
    container_name: ollama-web
    ports:
      - 3000:3000
    # volumes:
    #   - ./web:/web
    restart: unless-stopped
    networks:
      - ollama

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: ollama-backend
    ports:
      - 8000:8000
    volumes:
      - ./backend:/backend
    command: python manage.py runserver 0.0.0.0:8000
    restart: unless-stopped
    networks:
      - ollama

volumes:
  ollama:

networks:
  ollama:
    driver: overlay
    attachable: true